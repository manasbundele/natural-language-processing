import nltk
from jiwer import wer
import os
from os import listdir
from os.path import isfile, join


def load_data(path):
	with open(path, 'r') as file:
			contents = file.read().splitlines()

	return contents

def calculate_bleu_score(ground_truth_list, prediction_list, weights=(0.8,0.2,0,0)):
	# bleu: higher the better
	# weights is a tuple of weightage to (unigram, bigram, trigram, 4-gram)
	if len(ground_truth_list) == len(prediction_list):
		bleu_sum = 0
		x = nltk.translate.bleu_score.SmoothingFunction()
		for ii in range(len(prediction_list)):
			try:
					hypothesis = prediction_list[ii].lower().split()
					reference = ground_truth_list[ii].lower().split()
					
					BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis,smoothing_function=x.method1, weights=weights)
					bleu_sum += BLEUscore
			except Exception as e:
					#print("EXCEPTION: ", e)
					pass

		return bleu_sum/len(prediction_list)
	else:
		print("Error! ground truth and prediction list sizes dont match")
		return 0


def calculate_wer(ground_truth_list, prediction_list):
	# wer: lower the better
	if len(ground_truth_list) == len(prediction_list):
		total_wer = 0.0
		for ii in range(len(prediction_list)):
				try:
						hypothesis = prediction_list[ii].lower().split()
						reference = ground_truth_list[ii].lower().split()

						err = wer(reference, hypothesis, standardize=True)
						total_wer += err
				except Exception as e:
					#print("EXCEPTION: ", e)
					pass

		return total_wer/len(prediction_list)
	else:
		print("Error! ground truth and prediction list sizes dont match")
		return 1.0


def make_batch_api_calls_to_gnmts(input_list, output_file_path, batch_size=300, target_language='en'):
	# target language can be 'en' or 'hi' in our case
	prev = -1
	f = open(output_file_path, 'w+')
	for batch_no in range(prev+1,int(len(input_list)/batch_size)+1):
		try:
			translator = Translator()
			if (batch_no+1)*batch_size < len(input_list):
				batch_item = input_list[batch_no*batch_size:(batch_no+1)*batch_size]
			else:
				batch_item = input_list[batch_no*batch_size:len(input_list)+1]

			batch_res = translator.translate(batch_item, dest=target_language)
			translated_batch_text = [f.write(item.text + "\n") for item in batch_res]
			time.sleep(30)  
			print("batch ", batch_no, ": done.")
			prev += 1
		except Exception as e:
			# if error is : Expecting value: line 1 column 1 (char 0)
			# its because gnmts api call blacklist ip if continuous api calls are made
			print(e)
			print("ERROR! ", batch_no, "unsuccessful. If error is Expecting value: line 1 column 1 (char 0), its because google nmts blacklists an ip if continuous api calls are made! Sorry try again!")
			break

	f.close()


def main():
	# load augmentation file as it will be generated by baseline.py
	augmented_data = load_data('augmented.txt')
	en_contents = load_data('./code_mixed_dataset/english.txt')
	hien_contents = load_data('./code_mixed_dataset/hinglish.txt')

	if isfile("gnmts_translated.txt"):
		predicted = load_data("gnmts_translated.txt")
	else:
		make_batch_api_calls_to_gnmts(augmented_data, "gnmts_translated.txt")	
		predicted = load_data("gnmts_translated.txt")


	if isfile("gnmts_translated_without_augmentation.txt"):
		predicted_without_aug = load_data("gnmts_translated_without_augmentation.txt")
	else:
		make_batch_api_calls_to_gnmts(augmented_data, "gnmts_translated_without_augmentation.txt")	
		predicted_without_aug = load_data("gnmts_translated_without_augmentation.txt")

	without_aug_bleu = calculate_bleu_score(hien_contents, predicted_without_aug)

	without_aug_wer = calculate_wer(hien_contents, predicted_without_aug)

	print("Without augmentation: \n BLEU: ", without_aug_bleu,"\t WER: ", without_aug_wer)

	bleu_score = calculate_bleu_score(en_contents, predicted)

	wer_score = calculate_wer(en_contents, predicted)

	print("With augmentation: \n BLEU: ", bleu_score,"\t WER: ", wer_score)

	######## small test file - newly added code #####
	en_contents_test = load_data('./code_mixed_dataset/test_english.txt')
	predicted_test = load_data("test_gnmts_translated.txt")
	bleu_score = calculate_bleu_score(en_contents_test, predicted_test, (0.25,0.25,0.25,0.25))
	print("With augmentation test: \n BLEU avg: ", bleu_score)
	bleu_score = calculate_bleu_score(en_contents_test, predicted_test, (1.0,0.0,0.0,0.0))
	print("With augmentation test: \n BLEU 1: ", bleu_score)
	bleu_score = calculate_bleu_score(en_contents_test, predicted_test, (0.0,1.0,0.0,0.0))
	print("With augmentation test: \n BLEU 2: ", bleu_score)
	bleu_score = calculate_bleu_score(en_contents_test, predicted_test, (0.0,0.0,1.0,0.0))
	print("With augmentation test: \n BLEU 3: ", bleu_score)
	bleu_score = calculate_bleu_score(en_contents_test, predicted_test, (0.0,0.0,0.0,1.0))
	print("With augmentation test: \n BLEU 4: ", bleu_score)

	wer_score = calculate_wer(en_contents_test, predicted_test)

	print("With augmentation test: WER: ", wer_score)



if __name__ == "__main__":
	main()

